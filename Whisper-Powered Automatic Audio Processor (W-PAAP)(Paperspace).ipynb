{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPv5L4SfVB_a"
   },
   "source": [
    "# Whisper-Powered Automatic Audio Processor (W-PAAP)\n",
    "Notebook hackily created for Paperspace by NekoCitrus.\n",
    "\n",
    "Adapted from the OpenAI Whisper and PPP TalkNet notebooks.\n",
    "\n",
    "**Do not use this notebook alone to transcribe data.** Please make sure to verify and check your transcriptions before utilizing them for AI datasets/submitting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF3JYnfzVtzQ"
   },
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Check\n",
    "\n",
    "Use this cell to show information about your graphics card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-04-07T07:06:17.527134Z",
     "iopub.status.busy": "2023-04-07T07:06:17.526658Z",
     "iopub.status.idle": "2023-04-07T07:06:19.123815Z",
     "shell.execute_reply": "2023-04-07T07:06:19.121695Z",
     "shell.execute_reply.started": "2023-04-07T07:06:17.527134Z"
    },
    "id": "Q1Ib1p4uWSlO"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "Install dependencies for OpenAI Whisper and other assorted elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-04-07T07:06:28.979174Z",
     "iopub.status.busy": "2023-04-07T07:06:28.978730Z",
     "iopub.status.idle": "2023-04-07T07:07:00.797800Z",
     "shell.execute_reply": "2023-04-07T07:07:00.796780Z",
     "shell.execute_reply.started": "2023-04-07T07:06:28.979154Z"
    },
    "id": "IkHkWQmTWcF9"
   },
   "outputs": [],
   "source": [
    "!apt install unzip\n",
    "!python -m pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Configuration\n",
    "Configure paths of your audio ZIP file.\n",
    "\n",
    "Import your ZIP file to the root of the Paperspace filelist. Make sure that all your audio files are in the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-04-07T07:07:54.520376Z",
     "iopub.status.busy": "2023-04-07T07:07:54.518639Z",
     "iopub.status.idle": "2023-04-07T07:07:56.188713Z",
     "shell.execute_reply": "2023-04-07T07:07:56.187467Z",
     "shell.execute_reply.started": "2023-04-07T07:07:54.520314Z"
    },
    "id": "-p6nl1YGnjA9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "dataset = \"your_zip.zip\"\n",
    "character_folder_name = \"z\"\n",
    "\n",
    "pspaceName = \"/notebooks/\"+dataset\n",
    "assert os.path.exists(pspaceName), \"Cannot find your ZIP file.\"\n",
    "\n",
    "#Extract data.\n",
    "os.chdir('/notebooks')\n",
    "if os.path.exists(\"/wavs\"):\n",
    "    shutil.rmtree(\"/wavs\")\n",
    "os.mkdir(\"wavs\")\n",
    "#shutil.copyfile(pspaceName, \"/notebooks/wavs/\"+dataset)\n",
    "os.chdir(\"wavs\")\n",
    "\n",
    "if dataset[-4:] == \".zip\":\n",
    "    !unzip -q \"{pspaceName}\"\n",
    "#elif dataset[-4:] == \".tar\":\n",
    "#    !tar -xf \"{dataset}\"\n",
    "else:\n",
    "    raise Exception(\"Unknown extension for dataset.\")\n",
    "\n",
    "print(\"ZIP file successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-5j0-M8XM6R"
   },
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe\n",
    "Select your model and start transcription work. You should only need to run the first cell once, regardless of how much data you are feeding into the notebook.\n",
    "\n",
    "Do note that while the multilanguage version of the model should be downloaded, the only languages that most relevant voice AI solutions (15.ai/TalkNet/etc) support is English. If you are *positive* that all the speech in your audio files is in English, then feel free to use the English-Only models by appending \"-en\" to the model name.\n",
    "\n",
    "Set the \"Delete Useless\" value to True if you wish to automatically delete files that are knowingly unusable by 15.ai automatically. A file will also be generated with a list of all deleted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T07:08:19.527600Z",
     "iopub.status.busy": "2023-04-07T07:08:19.527102Z",
     "iopub.status.idle": "2023-04-07T07:08:37.884450Z",
     "shell.execute_reply": "2023-04-07T07:08:37.883194Z",
     "shell.execute_reply.started": "2023-04-07T07:08:19.527549Z"
    }
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "#Possible model options:\n",
    "# tiny - 39M parameters - requires 1GB VRAM\n",
    "# base - 74M parameters - requires 1GB VRAM\n",
    "# small - 244M parameters - requires 2GB VRAM\n",
    "# medium - 769M parameters - requires 5GB VRAM\n",
    "# large - 1550M parameters - requires 10GB VRAM (paid tier only, no English-Only model available)\n",
    "mod = \"small\" \n",
    "\n",
    "print(\"Loading Whisper model into memory...\")\n",
    "model = whisper.load_model(mod)\n",
    "options = whisper.DecodingOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-04-07T07:16:39.254613Z",
     "iopub.status.busy": "2023-04-07T07:16:39.254048Z",
     "iopub.status.idle": "2023-04-07T07:21:14.769033Z",
     "shell.execute_reply": "2023-04-07T07:21:14.767046Z",
     "shell.execute_reply.started": "2023-04-07T07:16:39.254552Z"
    },
    "id": "V3NQtADobYNj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import whisper\n",
    "\n",
    "delete_useless = True\n",
    "\n",
    "print(\"Model \\\"\"+mod+\"\\\" chosen.\")\n",
    "\n",
    "filename = \"transcription_for_\"+character_folder_name+\".txt\"\n",
    "if(os.path.exists(filename)):\n",
    "\tos.remove(filename)\n",
    "\n",
    "if(delete_useless):\n",
    "    if(os.path.exists(\"deleted_files.txt\")):\n",
    "        os.remove(\"deleted_files.txt\")\n",
    "\n",
    "def inference(audio):\n",
    "    if(delete_useless):\n",
    "        aud = whisper.load_audio(audio)\n",
    "        aud = whisper.pad_or_trim(aud)\n",
    "        mel = whisper.log_mel_spectrogram(aud).to(model.device)\n",
    "        _, probs = model.detect_language(mel)\n",
    "        lang = max(probs, key=probs.get)\n",
    "        if(lang!=\"en\"):\n",
    "            return \"\"\n",
    "        result = whisper.decode(model, mel, options)\n",
    "        return result.text\n",
    "    result = model.transcribe(audio)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def destroy_file(filename):\n",
    "    with open(\"deleted_files.txt\", 'a') as d:\n",
    "        d.write(filename+\"\\n\")\n",
    "    os.remove(filename)\n",
    "\n",
    "print(\"Writing transcriptions...\")\n",
    "\n",
    "for r, _, f in os.walk(\"/notebooks/wavs\"):\n",
    "    for name in tqdm(sorted(f)):\n",
    "        scrip=inference(os.path.join(r, name))\n",
    "\n",
    "        fname = name\n",
    "        if(delete_useless):\n",
    "            nopu = re.sub(r'[^\\w\\s]', '', scrip)\n",
    "            if(nopu == \"\" or (not nopu.isascii()) or len(nopu)<5):\n",
    "                destroy_file(name)\n",
    "                continue\n",
    "        finScript = character_folder_name + \"/\" + fname + \"|\" + scrip.lstrip()\n",
    "        with open(filename, 'a') as w:\n",
    "            w.write(finScript+\"\\n\")\n",
    "\n",
    "shutil.move(\"/notebooks/wavs/\"+filename, \"/notebooks/\")\n",
    "if(delete_useless):\n",
    "    shutil.move(\"/notebooks/wavs/deleted_files.txt\", \"/notebooks\")\n",
    "\n",
    "print(\"All done! Be sure to verify!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPi0oaFtLmUv3uPjctcV5/D",
   "collapsed_sections": [
    "EPv5L4SfVB_a"
   ],
   "provenance": [
    {
     "file_id": "1WpGumuesik_WHvL7Gwzm4j6QpAsn8RIy",
     "timestamp": 1675376604241
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
